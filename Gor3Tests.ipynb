{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test is a test notebook where I develop the GOR3 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "\n",
    "- The first thing we should do is import the data and clean the data to make it ready for use. \n",
    "- Understand the GOR 3 Algorithm\n",
    "- Understand how we should deal with edges \n",
    "- Understand what we need to do with invalid entries and how we deal with it in algorithm\n",
    "- Understand how we should make it optimised leave-one-out. (don't recount everything with every new protein sequence).\n",
    "- How to summarise the results of the GOR3 (per data set)\n",
    "- How to summarise the results per protein family.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to evaluate a protein. \n",
    "# Create a random protein sequence. Where the amino acids are code between 0,20\n",
    "Proteins = np.random.randint(3,size=100)\n",
    "SeqLen = len(Proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some invalid entries and pad the sides with -1's which represent the edges.\n",
    "Proteins[[15,74,87]] = -1 \n",
    "#Proteins = np.concatenate((-np.ones(8),Proteins,-np.ones(8))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create for now a dummy frequency tensor:\n",
    "freq = np.ones(shape=(3,17,3,3),dtype=float)\n",
    "freq[0,8,0,0] = 7\n",
    "freq[0,8,1,1] = 10\n",
    "freq[0,8,2,2] = 13\n",
    "freq[1,8,0,0] = 70\n",
    "freq[1,8,1,1] = 100\n",
    "freq[1,8,2,2] = 130\n",
    "\n",
    "\n",
    "CountSSperR = np.ones(shape=(3,20))\n",
    "CountSS = np.sum(CountSSperR,-1)\n",
    "otherSS = np.array([[1,2],[0,2],[0,1]]) # Have the index of the other Secundary Structure such that we can sum of the other SS\n",
    "logDiff = np.log(CountSS/np.sum(CountSS[otherSS],axis=-1))\n",
    "logDiffRj = np.log(CountSSperR/np.sum(CountSSperR[otherSS],axis=-2)) # -2 since -1 are the amino acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0,  2,  2,  1,  0,  2,  2,  0,  1,  1,  0,  2,  1, -1,  2,\n",
       "        0,  1,  0,  2,  2,  0,  1,  0,  2,  1,  2,  1,  1,  2,  0,  0,  1,\n",
       "        1,  1,  2,  2,  1,  1,  2,  2,  1,  0,  1,  2,  1,  1,  1,  0,  1,\n",
       "        2,  0,  2,  0,  2,  2,  2,  0,  1,  1,  0,  2,  1,  0,  2,  0,  1,\n",
       "        1,  0,  2,  1,  2,  2, -1,  1,  2,  1,  1,  2,  2,  1,  1,  1,  2,\n",
       "        1,  2, -1,  1,  1,  2,  1,  2,  0,  0,  0,  2,  1,  0,  0])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20., 20., 20.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-6849e0d7a39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmCorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmCorrect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 2 with size 3"
     ]
    }
   ],
   "source": [
    "valid = np.array([0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1]).astype(bool)\n",
    "seq = np.arange(17)\n",
    "vseq = seq[valid]\n",
    "mCorrect = np.where(valid)[0]\n",
    "freq[0,mCorrect,vseq,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "testarray = np.array([4,8,7])\n",
    "if 8 in testarray:\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.34 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "for i in range(500):\n",
    "    out = predictSS(Proteins,freq,logDiff,logDiffRj)\n",
    "Diff = time.time() - startTime\n",
    "print(f\"{np.round(Diff,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSS(protSequence, freq, logDiff, logDiffRj, SStrue, predictInvalidResidue=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - protSequence : 1D-numpy array, Represents the proteins sequence, where the aminoacids are labeled as integers from 0 to 19\n",
    "        - freq : 4D-numpy array shape = (3,17,20,20) representing the frequency count of the data set.\n",
    "            - axis0 = Secundary structure\n",
    "            - axis1 = relative position m from the window center positioned at j in the protein sequence\n",
    "            - axis2 = amino Acid at the position m. = R_{j+m}\n",
    "            - axis3 = amino Acid at the centre. = R_j\n",
    "        - logDiff: 1D-numpy array of length 3. This is the logarithm of the relative SS structure count: log(f_s/f_{not_s})\n",
    "        - logDiffRj: 2D-numpy array of shape (3,20). This is the logarithm of the relative SS structure count per amino accid: log(f_{s,R}/f_{not_s,R})\n",
    "        - SStrue\n",
    "        - dealWithInvalidResidue\n",
    "    Output:\n",
    "        - SS_result: 1D-numpy array with the predicted SS of the protein sequence\n",
    "        - ISS: 2D-numpy array with the information per SS per amino accid in the protein sequence.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Add 8 \"-1\"'s at the beginning and end of the protein sequence. \n",
    "    # This is done such that we can have running window of lenght 8 at each side at the edges of the protein sequences. \n",
    "    # Use -1 since we offcourse vieuw these as invalid entries.\n",
    "    paddedSequence = np.concatenate((-np.ones(8),protSequence,-np.ones(8))).astype(int)\n",
    "    SeqLen = len(protSequence)\n",
    "    otherSS = np.array([[1,2],[0,2],[0,1]]) # Have the index of the other Secundary Structure such that we can sum of the other SS\n",
    "    \n",
    "    # Construct the output value ISS\n",
    "    ISS = -np.ones(shape=(3,SeqLen)) # use -1 to later on detect invalid entries in the protein sequence.\n",
    "    \n",
    "    for j, r_j in enumerate(paddedSequence):\n",
    "        if j-8 > SeqLen: # We have reached the end.\n",
    "            break\n",
    "        if r_j<0: # We skip over invalid entries. (These are the padded edges and invalid entries)\n",
    "            continue\n",
    "        # r_j is valid so set the ISS level equalt to zero. Unvalid r_j are kept -1\n",
    "        ISS[:,j-8] = np.zeros(3)             \n",
    "        for SS in range(3):\n",
    "            for m, r_jm in enumerate(Proteins[j-8:j+9]): # m in [0,16],\n",
    "                if r_jm<0:\n",
    "                    continue\n",
    "                # Compute the logSum\n",
    "                ISS[SS,j-8] += np.log(freq[SS,m,r_jm,r_j]/np.sum(freq[otherSS[SS],m,r_jm,r_j]))\n",
    "                if m==8: \n",
    "                    ISS[SS,j-8] += logDiff[SS]\n",
    "                else:\n",
    "                    ISS[SS,j-8] += logDiffRj[SS,r_j]\n",
    "\n",
    "    SS_result = np.argmax(ISS,axis=0)\n",
    "    \n",
    "    if not predictInvalidResidue:\n",
    "        SS_result[protSequence<0] = -1 # Let the invalid protein sequences stay flagged as invalid.\n",
    "        return SS_result, ISS\n",
    "\n",
    "    ###################################################\n",
    "    ##### Deal with invalid amino acid entries ######\n",
    "    ##################################################\n",
    "    # This is not general yet !. \n",
    "    \n",
    "    InvalidResidue = np.logical_and(protSequence<0 and trueSS>=0) # Make sure that invalid entry is not duo a skip. \n",
    "    for index in InvalidResidue:\n",
    "        if index == 0: # The invalid is the first element\n",
    "            indexToCopy = 1\n",
    "            indexIsNotValid = np.any(Invalidindex==indexToCopy)\n",
    "            while indexIsNotValid: # Keep searching until we are sure that the next index is also not an invalid one. \n",
    "                indexToCopy+=1\n",
    "                nextIsValid = np.any(InvalidIndex==indexToCopy) and trueSS[indexToCopy]>=0\n",
    "            SS_result[index] = SS_result[indexToCopy] # Set it equal to the first valid element. \n",
    "        else: # In all other cases we pick the one below\n",
    "            SS_result[index] = SS_result[index-1]\n",
    "        # The reason why we pick the one is clarified by the logic that we would have else used:\n",
    "\n",
    "#       elif (index-1)==SeqLen # The invalid index is the last element\n",
    "#           SS_result[index] = SS_result[index-1] # Set equal to the element before.\n",
    "#       elif SS_result[index-1]==SS_result[index+1] # SS around in valid point is the same\n",
    "#           SS_result[index] = SS_result[index-1]\n",
    "#       else: # By default just pick the one below, this way we are sure the entry exist. \n",
    "#           SS_result[index]=SS_result[index-1] \n",
    "\n",
    "        # And so in all other cases it would have been pick the one below so. We can just simplify it with an easy else. \n",
    "\n",
    "    return SS_result, ISS # Return the found SS and the information values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Left to do now is reading in the data file and computing the frequency tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqTableOfProtein(protSequence,SS):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - protSequence : 1D-numpy array, Represents the proteins sequence, where the aminoacids are labeled as integers from 0 to 19\n",
    "        - SS : 1D-numpy array holding the know secundary structure of the \n",
    "    Output:\n",
    "    - freq : 4D-numpy array shape = (3,17,20,20) representing the frequency count of the protein sequence.\n",
    "            - axis0 = Secundary structure\n",
    "            - axis1 = relative position m from the window center positioned at j in the protein sequence\n",
    "            - axis2 = amino Acid at the position m. = R_{j+m}\n",
    "            - axis3 = amino Acid at the centre. = R_j\n",
    "    - countSS : returns the total counts of each type of secundary structure in the sequence\n",
    "    - coutSSperR: return the count of each type of secundary structure per amino acid.\n",
    "    \"\"\"\n",
    "    freqTable = np.zeros(shape=(3,17,20,20))\n",
    "    \n",
    "    # Pad the sequence with 8 -1's before and after such that we can easily perform move a window around. \n",
    "    paddedSequence = np.concatenate((-np.ones(8),protSequence,-np.ones(8))).astype(int)\n",
    "    paddedSS = np.concatenate((-np.ones(8),SS,-np.ones(8))).astype(int)\n",
    "    \n",
    "    seqLen = len(protSequence)\n",
    "    \n",
    "    #Fill freqTable\n",
    "    for j, (r_j, S_j) in enumerate(zip(paddedSequence,paddedSS)):\n",
    "        if j-8 > SeqLen: # We have reached the end.\n",
    "            break\n",
    "        if r_j<0: # We skip over invalid entries. (These are the padded edges and invalid entries)\n",
    "            continue\n",
    "        for m in np.arange(-8,9):#  m=[-8,...,8]\n",
    "            r_jm = paddedSequence[j+m]\n",
    "            if r_jm<0:\n",
    "                continue\n",
    "            freqTable[S_j,m+8,r_jm,r_j]+=1\n",
    "            \n",
    "    middleTable = freqTable[:,8] # take all the freq counts on m=0. \n",
    "    countSSperR = middleTable.diagonal(axis1=-1,axis2=-2) # Extract the diagonal\n",
    "    countSS = np.sum(countSSperR,axis=-1)\n",
    "    \n",
    "    return freqTable, countSS, countSSperR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaveOneOutAnalysis(dataSet = \"dssp\", protFamily = None, predictInvalidResidue = False ):\n",
    "    \"\"\"\n",
    "        Estimate the Q3 and CVV of the GOR method for a specific dataset using a crossvalidation of leave-one-out\n",
    "    \"\"\"\n",
    "    totalFreqTable = np.zeros(shape=(3,17,20,20))\n",
    "    totalCountSS = np.zeros(3)\n",
    "    totalCountSSperR = np.zeros(shape=(3,20))\n",
    "    otherSS = np.array([[1,2],[0,2],[0,1]]) # Have the index of the other Secundary Structure such that we can sum of the other SS\n",
    "    \n",
    "    # Select the correct proteinTuple based on dssp protFamily\n",
    "    \n",
    "    #First compute the full freqTable\n",
    "    for proteinSequence, trueSS in proteinTuple:\n",
    "        freqTableFromProt, countSSFromProt, countSSperRFromProt = freqTableOfProtein(proteinSequence, trueSS)\n",
    "        totalFreqTable += freqTableFromProt\n",
    "        totalCountSS += countSSFromProt\n",
    "        totalCountSSperR += countSSperRFromProt\n",
    "        \n",
    "    \n",
    "    numberProteins = len(AllProteins)\n",
    "    \n",
    "    Q3 = np.zeros(shape=(3,number))\n",
    "    CVV = np.zeros(shape=(3,number))\n",
    "    \n",
    "    # Now do the leave-one-out:\n",
    "    for i, (proteinSequence, trueSS) in enumerate(proteinTuple):\n",
    "        # Remove the frequency counts of this protein.\n",
    "        freqTableFromProt, countSSFromProt, countSSperRFromProt = freqTableOfProtein(proteinSequence, trueSS)\n",
    "        tempFreqTable = totalFreqTable - freqTableFromProt\n",
    "        tempCountSS = totalCountSS - countSSFromProt\n",
    "        tempCountSSperR = totalCountSSperR - countSSperRFromProt\n",
    "        \n",
    "        templogDiff = np.log(tempCountSS/np.sum(tempCountSS[otherSS],axis=-1))\n",
    "        templogDiffRj = np.log(tempCountSSperR/np.sum(tempCountSSperR[otherSS],axis=-2)) # -2 since -1 are the amino acids\n",
    "        \n",
    "        # Set Frequency that are equal to zero = 0.00001 inorder to avoid infinities.\n",
    "        tempFreqTable[tempFreqTable == 0] = 0.00001\n",
    "        \n",
    "        # Perform the GOR3 prediction.\n",
    "        SS_result, _ = predictSS(proteinSequence, tempFreqTable, templogDiff, templogDiffRj, trueSS, predictInvalidResidue)\n",
    "        \n",
    "        # Remove the dummy entrances, such that they not influence the Q3 and CVV calculations\n",
    "        # predictInvalidResidue = True, then invalid residue have also tried to be predicted. \n",
    "        # If we then now also remove them with the following code.\n",
    "        validEntries = SS_result>=0\n",
    "        SS_result = SS_result[validEntries]\n",
    "        trueSS = trueSS[validEntries]\n",
    "            \n",
    "        Q3[i] = proteinQ3(SS_result, trueSS)\n",
    "        CVV[i] = proteinCVV(SS_result, trueSS)\n",
    "    \n",
    "    return Q3, CVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proteinQ3(predictedSS, trueSS):\n",
    "    _, (numberHelix, numberSheet, numberCoil) = np.unique(trueSS, return_counts=True)\n",
    "    TPHelix = np.sum(np.logical_and(predictedSS==0, trueSS==0)) #Only look where trueSS = Helix, see if they are then equal.\n",
    "    TPSheet = np.sum(np.logical_and(predictedSS==1, trueSS==1))\n",
    "    TPCoil =  np.sum(np.logical_and(predictedSS==2, trueSS==2))\n",
    "    return np.array([TPHelix/numberHelix, TPSheet/numberSheet, TPCoil/numberCoil])\n",
    "\n",
    "def computeCVV(TP,TN,FP,FN):\n",
    "    numerator = TP*TN-FP*FN\n",
    "    denominator = np.sqrt((TP+FP) * (TP+FN) * (TN+FP) * (TN+FN))\n",
    "    return numerator/denominator\n",
    "\n",
    "def proteinCVV(predictedSS, trueSS):\n",
    "    #Helix\n",
    "    TPHelix = np.sum(np.logical_and(predictedSS==0, trueSS==0))\n",
    "    TNHelix = np.sum(np.logical_and(predictedSS!=0, trueSS!=0))\n",
    "    FPHelix = np.sum(np.logical_and(predictedSS==0, trueSS!=0))\n",
    "    FNHelix = np.sum(np.logical_and(predictedSS!=0, trueSS==0))\n",
    "    CVVHelix = computeCVV(TPHelix,TNHelix,FPHelix,FNHelix)\n",
    "    #Sheet\n",
    "    TPSheet = np.sum(np.logical_and(predictedSS==1, trueSS==1))\n",
    "    TNSheet = np.sum(np.logical_and(predictedSS!=1, trueSS!=1))\n",
    "    FPSheet = np.sum(np.logical_and(predictedSS==1, trueSS!=1))\n",
    "    FNSheet = np.sum(np.logical_and(predictedSS!=1, trueSS==1))\n",
    "    CVVSheet = computeCVV(TPSheet,TNSheet,FPSheet,FNSheet)\n",
    "    #Coil\n",
    "    TPCoil = np.sum(np.logical_and(predictedSS==2, trueSS==2))\n",
    "    TNCoil = np.sum(np.logical_and(predictedSS!=2, trueSS!=2))\n",
    "    FPCoil = np.sum(np.logical_and(predictedSS==2, trueSS!=2))\n",
    "    FNCoil = np.sum(np.logical_and(predictedSS!=2, trueSS==2))\n",
    "    CVVCoil = computeCVV(TPCoil,TNCoil,FPCoil,FNCoil)\n",
    "    return np.array([CVVHelix, CVVSheet, CVVCoil])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "So we have constructed all the relevant funtions. \n",
    "It is now time to extract the data from the input files and store them appropiately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some dictionary maps.\n",
    "aminoToNumber = {\"ALA\":0, \"ARG\":1, \"ASN\":2, \"ASP\":3, \"CYS\":4, \"GLN\":5, \"GLU\":6, \"GLY\":7, \"HIS\":8, \"ILE\":9, \"LEU\":10, \"LYS\":11, \"MET\":12, \"PHE\":13, \"PRO\":14, \"SER\":15, \"THR\":16, \"TRP\":17, \"TYR\":18, \"VAL\":19}\n",
    "shortAminoToNumber = {\"A\":0, \"R\":1, \"N\":2, \"D\":3, \"C\":4, \"Q\":5, \"E\":6, \"G\":7, \"H\":8, \"I\":9, \"L\":10, \"K\":11, \"M\":12, \"F\":13, \"P\":14, \"S\":15, \"T\":16, \"W\":17, \"Y\":18, \"V\":19}\n",
    "SStoNumber = {\"Helix\":0, \"Beta\":1, \"Coil\":2, \"Other\":2}\n",
    "shortSStoNumber = {\"H\":0, \"E\":1, \"C\":2}\n",
    "numberToStringSS = {0:\"H\", 1:\"E\", 2:\"C\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_code</th>\n",
       "      <th>PDB_chain_code</th>\n",
       "      <th>PDB_seq_code</th>\n",
       "      <th>residue_name</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1w0n</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>ILE</td>\n",
       "      <td>Coil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1w0n</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "      <td>THR</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1w0n</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1w0n</td>\n",
       "      <td>A</td>\n",
       "      <td>15</td>\n",
       "      <td>VAL</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1w0n</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>GLU</td>\n",
       "      <td>Beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71386</td>\n",
       "      <td>1ow4</td>\n",
       "      <td>A</td>\n",
       "      <td>114</td>\n",
       "      <td>VAL</td>\n",
       "      <td>Helix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71387</td>\n",
       "      <td>1ow4</td>\n",
       "      <td>A</td>\n",
       "      <td>115</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Helix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71388</td>\n",
       "      <td>1ow4</td>\n",
       "      <td>A</td>\n",
       "      <td>116</td>\n",
       "      <td>ASN</td>\n",
       "      <td>Helix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71389</td>\n",
       "      <td>1ow4</td>\n",
       "      <td>A</td>\n",
       "      <td>117</td>\n",
       "      <td>SER</td>\n",
       "      <td>Coil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71390</td>\n",
       "      <td>1ow4</td>\n",
       "      <td>A</td>\n",
       "      <td>118</td>\n",
       "      <td>TYR</td>\n",
       "      <td>Coil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71391 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PDB_code PDB_chain_code  PDB_seq_code residue_name     SS\n",
       "0         1w0n              A            12          ILE   Coil\n",
       "1         1w0n              A            13          THR   Beta\n",
       "2         1w0n              A            14          LYS   Beta\n",
       "3         1w0n              A            15          VAL   Beta\n",
       "4         1w0n              A            16          GLU   Beta\n",
       "...        ...            ...           ...          ...    ...\n",
       "71386     1ow4              A           114          VAL  Helix\n",
       "71387     1ow4              A           115          ARG  Helix\n",
       "71388     1ow4              A           116          ASN  Helix\n",
       "71389     1ow4              A           117          SER   Coil\n",
       "71390     1ow4              A           118          TYR   Coil\n",
       "\n",
       "[71391 rows x 5 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"inputData/dssp_info.txt\", sep=\"\\t\", header=None, names=[\"PDB_code\", \"PDB_chain_code\", \"PDB_seq_code\", \"residue_name\", \"SS\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Convert residue names and secundary structures to numbers which represent the coordinates of the frequency tensors. Residue names that are not of the standard 20 will be converted to -1 and thus flagged as invalid residue entry. This way the running window of the GOR algorithm knows to ignore those entries.\n",
    "\n",
    "We can then later also choise if we want to predict the SS of those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['residue_name'] = pd.to_numeric( df['residue_name'].map(aminoToNumber).fillna(-1), downcast='signed')# Fill non matching (aka the not standard amino acids) = -1\n",
    "df[\"SS\"] = pd.to_numeric( df[\"SS\"].map(SStoNumber), downcast=\"signed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by `PDB_code` and `PDB_chain_code` code, since there are instance of proteins in multiple configurations. Instances of these proteins have been given an different \"chain code\". As far as we are consered in our analysis we treat these as different proteins since they have a different structure. Hence our GOR algorithm should get the information of both configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = output.groupby([\"PDB_code\",\"PDB_chain_code\"], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proteins with multpliple chain configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1n7s\n",
      "1wmh\n",
      "1n7s\n",
      "1n7s\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "for (proteinCode , chainCode), _ in proteins:\n",
    "    if proteinCode in dictionary:\n",
    "        print(proteinCode) # Just print such that we do not have to manually search later on in the dict.\n",
    "        dictionary[proteinCode] += 1\n",
    "    else:\n",
    "        dictionary[proteinCode] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the protein instance \"1n7s\" comes in 4 configurations for the dssp data set and \"1wmh\" in 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the skips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteincode ChainCode residuesSkipped\n",
      "1j3a A 13\n",
      "1mj4 A 1\n",
      "1xod A 9\n",
      "1jni A 5\n",
      "2pvb A 1\n",
      "2hly A 2\n",
      "1ltz A 3\n",
      "3r9f A 316\n",
      "3lax A 3\n",
      "1luc A 29\n",
      "3mxz A 1\n",
      "2pq7 A 43\n",
      "1jl0 A 15\n",
      "1nu0 A 7\n",
      "3g02 A 7\n",
      "2hc1 A 7\n",
      "2iyv A 3\n",
      "3bld A 24\n",
      "1ekq A 15\n",
      "2o9u X 1\n",
      "1w5q A 10\n",
      "1fye A 9\n",
      "3ess A 9\n",
      "1g4y B 1\n",
      "3q62 A 2\n",
      "3gp6 A 8\n",
      "2ril A 4\n",
      "3bs4 A 8\n",
      "3b4q A 3\n",
      "1dg6 A 13\n",
      "1qg8 A 17\n",
      "2oqz A 5\n",
      "3elf A 13\n",
      "1nqj A 4\n",
      "2vpa A 11\n",
      "3jud A 6\n",
      "1nnx A 13\n",
      "1b8z A 23\n",
      "3bvf A 834\n",
      "1od6 A 5\n",
      "1oi0 A 13\n",
      "2r4q A 2\n",
      "1nn5 A 5\n",
      "1vke A 1\n",
      "2fco A 17\n",
      "1vju A 11\n",
      "1xbi A 1\n",
      "1v05 A 2633\n",
      "3lb2 A 4\n",
      "1v2b A 23\n",
      "2bog X 6\n",
      "1zk5 A 3\n",
      "2pag A 3\n",
      "2prx A 32\n",
      "1wpu A 1852\n",
      "2icu A 10\n",
      "1mnn A 13\n",
      "3bt5 A 2\n",
      "1m1f A 3\n",
      "2eng A 5\n",
      "2v9l A 1\n",
      "2za4 B 1\n",
      "1ymt A 8\n",
      "1s9u A 6\n",
      "2qt1 A 5\n",
      "1m22 A 3\n",
      "2okf A 7\n",
      "1tzp A 15\n",
      "2ij2 A 3\n",
      "1usm A 3\n",
      "3b5o A 7\n",
      "2aeb A 232\n",
      "2ap3 A 5\n",
      "3fcx A 14\n",
      "1cxq A 4\n",
      "1ryl A 7\n",
      "1k4n A 7\n",
      "2gyq A 7\n",
      "2qzc A 2\n",
      "1xju A 2\n",
      "2wnv B 1\n",
      "2fup A 2\n",
      "3h7c X 7\n",
      "1fcq A 7\n",
      "1z67 A 2\n",
      "1jhg A 2\n",
      "2brf A 1\n",
      "2ggc A 836\n",
      "1p5z B 12\n",
      "1f9v A 29\n",
      "1gpp A 239\n",
      "1vyk A 20\n",
      "3bhd A 3\n",
      "1df4 A 5\n",
      "3eoj A 2\n",
      "2zfg A 1\n",
      "1x9d A 1\n",
      "2y1q A 5\n",
      "3ed7 A 23\n",
      "1z72 A 1\n",
      "1lyq A 3\n",
      "1ujp A 28\n",
      "2fsr A 6\n",
      "3f0d A 4\n",
      "1z70 X 10\n",
      "1hq1 A 7\n",
      "3d06 A 13\n",
      "1of8 A 7\n",
      "1mc2 A 12\n",
      "1pp0 A 3\n",
      "2o8q A 7\n",
      "2w15 A 1001\n",
      "1xdz A 1\n",
      "2bcm A 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Proteincode\", \"ChainCode\",\"residuesSkipped\")\n",
    "for (proteinCode, chainCode), protein in proteins:\n",
    "    rPosition= protein[\"PDB_seq_code\"].values\n",
    "    skipped = np.diff(rPosition)-1\n",
    "    totalSkipped = np.sum(skipped)\n",
    "    if totalSkipped!=0:\n",
    "        print(proteinCode+\" \"+chainCode,totalSkipped) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that actually many proteins have just missing entries. For instance the first one has directly apperentally 13 missing. \n",
    "\n",
    "Let's have a closer look to where exactly this happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped exactly here:\n",
      "[53,67]\n",
      "Given sequence position:\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
      " 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
      " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142]\n"
     ]
    }
   ],
   "source": [
    "def printSkips(code, chainCode):\n",
    "    rPosition = proteins.get_group((code, chainCode))[\"PDB_seq_code\"].values\n",
    "    skipped = np.diff(rPosition)-1\n",
    "    indexesSkipped = np.where(skipped!=0)[0]\n",
    "    print(\"Skipped exactly here:\")\n",
    "    for index in indexesSkipped:\n",
    "        print(f\"[{rPosition[index]},{rPosition[index+1]}]\")\n",
    "    print(\"Given sequence positions:\")\n",
    "    print(rPosition)\n",
    "printSkips(code = \"1j3a\",chainCode = \"A\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the skip happens at position 53 -> 67\n",
    "\n",
    "In order to really understand the data and see indeed that it meant that indeed 13 entries were missing and that we could indeed trust the `PDB_seq_code` as the sequence number of the proteins. I had a look at the PDB for protein \"1j3a\", and indeed looking around in the files I found:\n",
    "\n",
    "> REMARK 465                                                                      \n",
    "REMARK 465 MISSING RESIDUES                                                     \n",
    "REMARK 465 THE FOLLOWING RESIDUES WERE NOT LOCATED IN THE                       \n",
    "REMARK 465 EXPERIMENT. (M=MODEL NUMBER; RES=RESIDUE NAME; C=CHAIN               \n",
    "REMARK 465 IDENTIFIER; SSSEQ=SEQUENCE NUMBER; I=INSERTION CODE.)                \n",
    "REMARK 465                                                                      \n",
    "REMARK 465   M RES C SSSEQI                                                     \n",
    "REMARK 465     GLY A    54                                                      \n",
    "REMARK 465     LEU A    55                                                      \n",
    "REMARK 465     ARG A    56                                                      \n",
    "REMARK 465     THR A    57                                                      \n",
    "REMARK 465     LEU A    58                                                      \n",
    "REMARK 465     THR A    59                                                      \n",
    "REMARK 465     ASN A    60                                                      \n",
    "REMARK 465     PRO A    61                                                      \n",
    "REMARK 465     ARG A    62                                                      \n",
    "REMARK 465     ARG A    63                                                      \n",
    "REMARK 465     GLY A    64                                                      \n",
    "REMARK 465     PRO A    65                                                      \n",
    "REMARK 465     PHE A    66 \n",
    "\n",
    "So indeed the protein sequence is know for sequence number 54->66. But in the experiment they could not locate the position of the residues, hence one can then also not say in what structure they are organised. It's for this reason that those entries are simply not listed in our input data.\n",
    "\n",
    "And hence we can assume going forward that this is the case with all other proteins that have missing entries.\n",
    "\n",
    "---\n",
    "So we found appart from residue entries that are not one of the standard 20 amino acids. We also have entries where the SS is simply not know. And these we could detect as presented above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing around with the function `printSkips` to investigate it is found that most often the proteins with extremely large skips >1000. That those from entries where just a few residues are added in the beginning or the ending. These are so distant from the main sequence that they do not contain any information from neighbouring residues. However, we will keep them since they still provide information on that particular residues itself like in GOR I.\n",
    "\n",
    "\n",
    "We see that it is also sometimes possible that multiple skipps happen, as is seen in protein number:\"1gpp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with the skips:\n",
    "\n",
    "It is important that the relative distance between residues is respected, since this is essential in our GOR analysis! \n",
    "\n",
    "As was said with the residues, we will flag invalid residue entries with -1 to let the running window know to ignore these entries. What we will do with the skips is add new entries to our data that will also be flagged as invalid since for those added entries we do not know the SS. \n",
    "\n",
    "It is important that we add these, since if for instance a skip of 1 happens well then the amino acid on the left of the skip needs to know that the amino acid on the right is not its neighbour (m=1) but its next to neirest neighbour (m=2). \n",
    "\n",
    "We only add up to 8 invalid dummy entries. Since one side of our window is only 8 wide (eg. [-8 to -1] and [1 to 8]) and invalid entries are automatically skipped when the window at m=0 goes over them. Thus skips larger then 8 only get 8 invalid dummy entries added between them, this then also ensures that our data does not grow unnecassary big if a skip of 2000 happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further prepare the input data for analysis.\n",
    "\n",
    "As said above we now need to add our dummy entrances.\n",
    "\n",
    "We will not be doing this in the pandas dataframe since then we also need entries for the other columns while we just want to focus on the sequence. So we just create our own dictionary and store there the updated sequences in numpy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(dataSet = \"dssp\", protFamily = None):\n",
    "    pd.read_csv(\"inputData/\"+dataSet+\"_info.txt\", sep=\"\\t\", header=None, names=[\"PDB_code\", \"PDB_chain_code\", \"PDB_seq_code\", \"residue_name\", \"SS\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
